# Machine Learning / High Dimensional Statistics

## Distributed Inference

1. Distributed Inference for PCA
2. Communication-Efficient Distributed Statistical Inference
3. Communication-Efficient Algorithms for Statistical Optimization
4. Distributed Estimation of Principal Eigenspaces

## Concentration Inequalities

1. Sum-of-Squares Lower Bounds for Sparse PCA
2. The Masked Sample Covariance Estimator- an Analysis Using Matrix Concentration Inequalities

## Variational Inference

1. Black Box Variational Inference
2. Variational Inference - A Review for Statisticians
3. Variational Inference with Normalizing Flow
4. MADE- Masked Autoencoder for Distribution Estimation
5. Masked Autoregressive Flow for Density Estimation
6. Neural Autoregressive Distribution Estimation

## MCMC

1. MCMC using Hamiltonian dynamics

## General Machine Learning

1. [Latent Dirichlet Allocation](../notes/LDA.html)
2. [Relational Dependency Networks](../notes/RDN.html)

## Traditional Learning Theory

1. Simplified PAC-Bayesian Margin Bounds
2. Boosting the Margin_A New Explanation for the Effectiveness of Voting Methods
3. The Weighted Majority Algorithm
4. The Strength of Weak Learnability
5. The Multiplicative Weights Update Method- A Meta-Algorithm and Applications

## Computation Method

1. A scalable bootstrap for massive data

## Subspace Clustering

1. Mixtures of Probabilistic Principal Component Analysers
2. Robust Recovery of Subspace Structures by Low-Rank Representation
3. A tutorial on subspace clustering

## Crowdsourcing

1. Eliminating Spammers and Ranking Annotators for Crowdsourced Labeling Tasks
2. Obtaining High-Quality Label by Distinguishing between Easy and Hard Items in Crowdsourcing
3. Double or Nothing: Multiplicative Incentive Mechanisms for Crowdsourcing 
4. Repeated labeling using multiple noisy labelers
5. Get Another Label? Improving Data Quality and Data Mining Using Multiple, Noisy Labelers