# Numerical and Optimization

## Numerical Computation

1. The Evaluation of Integrals of the form $$\int^{+\infty}_{-\infty} f(t)\exp^{−t^2} dt$$: Application to Logistic-Normal Models
2. Faster Eigenvector Computation via Shift-and-Invert Preconditioning

## Generalization

1. Local Optimality and Generalization Guarantees for the Langevin Algorithm via Empirical Metastability

## Optimization

1. A Differential Equation for Modeling Nesterov’s Accelerated Gradient Method
2. SARAH: A Novel Method for Machine Learning Problems Using Stochastic Recursive Gradient
3. Accelerating Stochastic Gradient Descent using Predictive Variance Reduction
4. Semi-Stochastic Gradient Descent Methods
5. [Faster Rates for the Frank-Wolfe Method over Strongly-Convex Sets](../notes/Faster_Frank_Wolfe.html)

## Principal Component Analysis

1. Fast and Simple PCA via Convex Optimization
2. Gradient Descent Meets Shift-and-Invert Preconditioning for Eigenvector Computation
3. Faster Eigenvector Computation via Shift-and-Invert Preconditioning
4. LazySVD: Even Faster SVD Decomposition Yet Without Agonizing Pain
5. Fast Stochastic Algorithms for SVD and PCA- Convergence Properties and Convexity